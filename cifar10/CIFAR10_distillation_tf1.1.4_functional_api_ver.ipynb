{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import argparse\n",
    "import h5py\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import Iterator\n",
    "# from keras.engine.topology import Input, Container\n",
    "from keras.engine.training import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, advanced_activations, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Convolution2D, pooling, Lambda, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model as keras_load_model\n",
    "from keras.callbacks import Callback\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "import os\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import  Model,load_model\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Input,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 32, 32, 3)\n",
      "x_test.shape: (10000, 32, 32, 3)\n",
      "y_train.shape: (50000, 1)\n",
      "y_test.shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# データ次元確認\n",
    "print('x_train.shape:', x_train.shape)\n",
    "print('x_test.shape:', x_test.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# 正規化\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "# one hot ベクトル化\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 蒸留モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_distillation_loss(input_distillation):\n",
    "    y_pred, y_true, y_soft, y_pred_soft = input_distillation\n",
    "    return (1 - args.lambda_const) * logloss(y_true, y_pred) + \\\n",
    "           args.lambda_const * args.temperature * args.temperature * logloss(y_soft, y_pred_soft)\n",
    "\n",
    "\n",
    "class MyIterator(object):\n",
    "    def __init__(self, iterator_org):\n",
    "        self.iterator = iterator_org\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        tmp = next(self.iterator)\n",
    "        return [tmp[0], tmp[1]], tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BornAgainModel(object):\n",
    "    def __init__(self, teacher_model):\n",
    "        self.train_model, self.born_again_model = None, None\n",
    "        self.temperature = args.temperature\n",
    "        self.teacher_model = keras_load_model(teacher_model)\n",
    "        for i in range(len(self.teacher_model.layers)):\n",
    "            self.teacher_model.layers[i].trainable = False\n",
    "        self.teacher_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "        self.train_model, self.born_again_model = self.prepare()\n",
    "        self.train_model = convert_gpu_model(self.train_model)\n",
    "\n",
    "    def prepare(self):\n",
    "#         self.teacher_model.summary()\n",
    "        self.teacher_model.layers.pop()\n",
    "        input_layer = self.teacher_model.input\n",
    "        teacher_logits = self.teacher_model.layers[-1].output\n",
    "        teacher_logits_T = Lambda(lambda x: x / self.temperature)(teacher_logits)\n",
    "        teacher_probabilities_T = Activation('softmax', name='softmax1_')(teacher_logits_T)\n",
    "\n",
    "        \"\"\"生徒モデル作成部分\n",
    "        \"\"\"\n",
    "        # 1/4に設定\n",
    "        x = Conv2D(16,(3,3),padding = \"SAME\",activation= \"relu\")(input_layer)\n",
    "        x = Conv2D(16,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(32,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
    "        x = Conv2D(32,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "        x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
    "        x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # 1024->512\n",
    "        x = Dense(512,activation = \"relu\")(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \"\"\"生徒モデル作成部分\n",
    "        \"\"\"\n",
    "        \n",
    "        logits = Dense(num_classes, activation=None, name='dense2')(x)\n",
    "        output_softmax = Activation('softmax', name='output_softmax')(logits)\n",
    "        logits_T = Lambda(lambda x: x / self.temperature, name='logits')(logits)\n",
    "        probabilities_T = Activation('softmax', name='probabilities')(logits_T)\n",
    "\n",
    "        with tf.device('/cpu:0'):\n",
    "            born_again_model = Model(inputs=input_layer, outputs=output_softmax)\n",
    "            input_true = Input(name='input_true', shape=[None], dtype='float32')\n",
    "        output_loss = Lambda(knowledge_distillation_loss, output_shape=(1,), name='kd_')(\n",
    "            [output_softmax, input_true, teacher_probabilities_T, probabilities_T]\n",
    "        )\n",
    "        inputs = [input_layer, input_true]\n",
    "\n",
    "        with tf.device('/cpu:0'):\n",
    "            train_model = Model(inputs=inputs, outputs=output_loss)\n",
    "\n",
    "        return train_model, born_again_model\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred = self.born_again_model.predict(x_test)\n",
    "        acc = 0\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if np.argmax(y_pred[i][:num_classes]) == np.argmax(y_test[i]):\n",
    "                acc = acc + 1\n",
    "\n",
    "        return acc / y_pred.shape[0]\n",
    "    \n",
    "def convert_gpu_model(org_model: Model) -> Model:\n",
    "    gpu_count = len(device_lib.list_local_devices()) - 1\n",
    "    if gpu_count > 1:\n",
    "        train_model = multi_gpu_model(org_model, gpu_count)\n",
    "    else:\n",
    "        train_model = org_model\n",
    "    return train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 # cifar10用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\12810649\\appdata\\local\\continuum\\anaconda3\\envs\\tf1.1.4\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "output_softmax (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 110,490\n",
      "Trainable params: 110,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "        \"temperature\": 10.0,\n",
    "        \"lambda_const\": 0.9,\n",
    "        \"teacher_model_path\": './models/cifar10_tf114_functional_api_ver_200604.h5'\n",
    "})\n",
    "\n",
    "\n",
    "distilmodel = BornAgainModel(args.teacher_model_path)\n",
    "print()\n",
    "distilmodel.born_again_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.7772 - acc: 0.3223 - val_loss: 1.5927 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 1.3815 - acc: 0.4872 - val_loss: 1.3935 - val_acc: 0.4809\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 1.1898 - acc: 0.5619 - val_loss: 1.1520 - val_acc: 0.5950\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 1.0753 - acc: 0.6110 - val_loss: 1.0875 - val_acc: 0.6135\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 0.9840 - acc: 0.6486 - val_loss: 0.9765 - val_acc: 0.6521\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.9178 - acc: 0.6733 - val_loss: 1.0104 - val_acc: 0.6395\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 0.8599 - acc: 0.6944 - val_loss: 1.0279 - val_acc: 0.6350\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 0.8211 - acc: 0.7089 - val_loss: 0.9045 - val_acc: 0.6777\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.7832 - acc: 0.7228 - val_loss: 0.8157 - val_acc: 0.7123\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 0.7433 - acc: 0.7375 - val_loss: 0.7906 - val_acc: 0.7232\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.7180 - acc: 0.7480 - val_loss: 0.8941 - val_acc: 0.6846\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 0.6893 - acc: 0.7582 - val_loss: 0.7735 - val_acc: 0.7293\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.6610 - acc: 0.7640 - val_loss: 0.7880 - val_acc: 0.7210\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 0.6402 - acc: 0.7733 - val_loss: 0.7833 - val_acc: 0.7209\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 0.6143 - acc: 0.7817 - val_loss: 0.7116 - val_acc: 0.7499\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 0.5968 - acc: 0.7888 - val_loss: 0.7080 - val_acc: 0.7559\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 0.5788 - acc: 0.7947 - val_loss: 0.7371 - val_acc: 0.7435\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 0.5643 - acc: 0.8021 - val_loss: 0.7235 - val_acc: 0.7514\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 0.5474 - acc: 0.8069 - val_loss: 0.7025 - val_acc: 0.7540\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 0.5262 - acc: 0.8137 - val_loss: 0.7534 - val_acc: 0.7442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27eeaa1f988>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilmodel.born_again_model.compile(loss = \"categorical_crossentropy\",optimizer = Adam(), metrics = [\"accuracy\"])\n",
    "distilmodel.born_again_model.fit(x_train,\n",
    "                              y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=20,\n",
    "                              validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/step\n",
      "Test loss: 0.7665595895767212\n",
      "Test accuracy: 0.7378\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = distilmodel.born_again_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\12810649\\Projects\\dnn_samples\\cifar10\\models\\cifar10_distillation_tf114_functional_api_ver_200604.h5 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Save model and weights\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'cifar10_distillation_tf114_functional_api_ver_200604.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "distilmodel.born_again_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
